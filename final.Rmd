---
title: "Machine Learning Final Project"
author: "Edward Cox"
date: "June 9, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rattle)
```

## Using Machine Learning to Predict the Manner of Exercise

6 volunteers were outfitted with accelerometers on the belt, arm, forearm, and dumbbell and asked to perform lifts correctly and incorrectly in 5 different ways.  The goal of this project is to identify the manner (A-E) in which the exercise was being performed.

We will build a model using random forests to predict outcomes.

```{r data}
set.seed(10101)
d <- read.csv("pml-training.csv")

# Cross validation method - random partitions
inTrain  <- createDataPartition(d$classe, p = 0.7, list = FALSE)
training <- d[inTrain,]
testing  <- d[-inTrain,]

# First 7 cols do not apply to model so we can remove them
training <- training[,-c(1:7)]
```

## Remove covariates with near-zero variation

Variables that exhibit little or no variation are useless for prediction and should be removed from the model.

```{r remove_near_zero}
my.nzv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[,rownames(my.nzv[my.nzv$nzv == FALSE,])]
```

## Handle missing values

The train function fails if there are missing values (NAs).  We must decide how to handle them.

```{r handle_NAs}
# Handle missing values
sum(colSums(is.na(training))/nrow(training) > 0) # num cols that contain missing values
sum(colSums(is.na(training))/nrow(training) == 0) # num cols that do not contain missing values
sum(colSums(is.na(training))/nrow(training) > .9) # num cols that contain more than 90% missing values

## Since every column that contains some missing values contains almost no data, remove these columns
training <- training[,colSums(is.na(training))/nrow(training) == 0]
```

## Apply changes to testing set

If we remove a column from the training set, we must also remove it from the testing set.

```{r update_testing}
# Remove same columns from testing set that we removed from training set
testing <- testing[,names(training)]
```

## Train model

Our random forest model uses 52 variables to predict the "classe" of exercise.

```{r train_model}
modFit <- train(classe ~ ., data = training, method = "rf", ntree = 4)
```

## Expected out-of-sample error

Let's estimate the accuracy of the model by looking at how well it predicts the classe variable in the testing partition.

```{r confusion}
confusionMatrix(testing$classe, data = predict(modFit, newdata = testing))
```

## Conclusions

The final model predicts the correct classe about 97% of the time, so the out-of-sample error rate is about 3%.